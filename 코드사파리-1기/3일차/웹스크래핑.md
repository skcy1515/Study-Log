# 웹스크래핑이란?
웹 스크래핑(web scraping)은 웹 페이지에서 우리가 원하는 부분의 데이터를 수집해오는 것을 뜻합니다.

# 웹스크래핑 해보기
https://www.imdb.com/chart/top/?ref_=nv_mv_250

![image](https://github.com/user-attachments/assets/e560f8a3-9825-4762-a9ae-a962995e1cf0)

![image](https://github.com/user-attachments/assets/151b5b1f-8de4-445b-9edd-cad97277426d)

개발자 도구를 열어서 HTML 구조 확인

```
import requests
from bs4 import BeautifulSoup
    
# 타겟 URL을 읽어서 HTML를 받아오고,
headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}
data = requests.get('https://www.imdb.com/chart/top/?ref_=nv_mv_250', headers=headers)
    
# HTML을 BeautifulSoup이라는 라이브러리를 활용해 검색하기 용이한 상태로 만듦
# soup이라는 변수에 "파싱 용이해진 html"이 담긴 상태가 됨
# 이제 코딩을 통해 필요한 부분을 추출하면 된다.
soup = BeautifulSoup(data.text, 'html.parser')
print(soup)  # HTML을 받아온 것을 확인할 수 있다.
```
이후 파이썬 파일 생성 후 코드 복붙

### User-Agent
- HTTP 요청에 포함되는 헤더 중 하나로, 요청을 보낸 클라이언트(사용자)의 정보를 나타낸다.
- 여기에는 클라이언트의 운영체제, 브라우저 종류 및 버전 등의 정보가 포함된다.
- 구성 요소 설명:
  - Mozilla/5.0: 브라우저가 Mozilla 기반(대부분의 현대 브라우저)임을 나타낸다.
  - Windows NT 10.0; Win64; x64: 클라이언트가 Windows 10 64비트 운영체제에서 실행되고 있음을 나타낸다.
  - AppleWebKit/537.36: 웹킷 기반 브라우저(예: Chrome, Safari)임을 나타낸다.
  - Chrome/73.0.3683.86: 사용 중인 Chrome 브라우저의 버전.
  - Safari/537.36: Safari와 호환성을 가지는 브라우저임을 나타낸다.

- `requests.get(url, headers=headers)` : 해당 URL로 HTTP GET 요청을 보낸다. IMDb 서버로부터 응답(HTML 데이터)을 받아온다.
- `data.text` : `requests.get()`으로 받아온 응답 데이터를 텍스트(HTML)로 변환한다.
- `BeautifulSoup(data.text, 'html.parser')` : HTML 데이터를 파싱하여 BeautifulSoup 객체로 변환한다.

* HTML 파싱: "웹사이트 코드에서 내가 필요한 데이터만 뽑아오는 작업."

```
# select를 이용해서, li들을 불러오기
# class 명 앞에는 '.'을 붙여줍니다.
# class 명 내의 띄어쓰기(공백)은 '.'으로 바꾸어 써주세요.
# class는 맨 뒤에 것을 가져옴
movies = soup.select('.ipc-page-grid__item--span-2 > .ipc-metadata-list--base > li')
    
print(len(movies)) # 25
    
for movie in movies:
  print(movie)
```

위에서 파악한 구조를 이용하여 우선 select()를 이용해 영화들을 찾아봅니다.

![image](https://github.com/user-attachments/assets/78943d7d-8e44-4894-a2de-d2f8f13fa254)

```
# movies(li들)의 반복문을 돌리기
for movie in movies:
  # movie 안에 h3 가 있으면,
  # (조건을 만족하는 첫 번째 요소, 없으면 None을 반환한다.)
  tag_element = movie.select_one('.ipc-title-link-wrapper > h3')
  print(tag_element)
```
![image](https://github.com/user-attachments/assets/e458d59b-4823-4466-9b9a-abb22df3a21b)

각 영화에서 영화 제목이 적혀 있는 a 태그를 select_one()으로 찾아봅니다.

```
# movies(li들)의 반복문을 돌리기
for movie in movies:
  # movie 안에 h3가 있으면,
  # (조건을 만족하는 첫 번째 요소, 없으면 None을 반환한다.)
  tag_element = movie.select_one('.ipc-title-link-wrapper > h3')
  if not tag_element:
    continue
  # h3의 text를 찍어본다.
  print(tag_element.text)
```
![image](https://github.com/user-attachments/assets/80e0bd29-986a-44a9-a6c0-25bfc79f61ce)

그중 내용이 있는 경우에만 텍스트를 프린트하도록 합니다.

## 또 다른 예시들
```
movies = soup.select('.ipc-title__text')
for movie in movies:
    print(movie.text)
```
그냥 li 안에 있는 태그들이 다 같다면 이렇게 간단하게 할 수 있다.

```
movie = soup.select_one('#__next > main > div > div.ipc-page-content-container.ipc-page-content-container--center > section > div > div.ipc-page-grid.ipc-page-grid--bias-left > div > ul > li:nth-child(2) > div > div > div > div > div.sc-6ae44812-0.geqCkX.cli-children > div.ipc-title.ipc-title--base.ipc-title--title.ipc-title-link-no-icon.ipc-title--on-textPrimary.sc-3713cfda-2.fSzZES.cli-title.with-margin > a > h3')
print(movie.text) # 2. Daeboo
```

그리고 개발자 도구에서 copy -> copy selector를 이용해 그 선택자의 값을 뽑아올 수 있다 

## beautifoulsoup4 사용법
```
# 선택자를 사용하는 방법 (copy selector)
    soup.select('태그명')
    soup.select('.클래스명')
    soup.select('#아이디명')
    
    # class 명 내의 띄어쓰기(공백)은 '.'으로 바꾸어 쓰거나, 조건이 겹치지 않는다면 띄어쓰기를 기준으로 class들을 분리하고 마지막 class만 써주세요.
    # 위의 단순한 3가지 형태만 쓸 경우 여러 요소가 선택될 수도 있습니다.
    # 예: soup.select('a')는 문서 내의 모든 <a></a> 요소를 찾습니다.
    # 이를 좀 더 구체화해서 아래처럼 어떤 경로를 거쳐 요소를 찾아야 되는지 명시할 수 있습니다. 
    soup.select('상위태그명 > 하위태그명 > 하위태그명')
    soup.select('상위태그명.클래스명 > 하위태그명.클래스명')
    
    # 앞의 예에서처럼 여러 <li>를 가질 때 몇 번째 <li> 인지를
    # 부모의 몇 번째 자식인지 명시해서 지정할 수도 있습니다. 
    soup.select('.클래스명:nth-child(자식의순서)')
    
    # 태그와 속성값으로 찾는 방법
    soup.select('태그명[속성="값"]')
    
    # 한 개만 가져오고 싶은 경우
    soup.select_one('위와 동일')
```
- 위에서 본 것처럼 select()는 조건을 만족하는 모든 요소를 리스트에 담아 반환하고, select_one()은 그중 가장 위에 나오는 요소를 반환합니다.
- 선택자는 CSS를 작성할 때 썼던 것과 똑같이 쓰면 됩니다.

# 웹스크래핑 더 해보기 (2.py)
```
# HTML을 BeautifulSoup이라는 라이브러리를 활용해 검색하기 용이한 상태로 만듦
# soup이라는 변수에 "파싱 용이해진 html"이 담긴 상태가 됨
# 이제 코딩을 통해 필요한 부분을 추출하면 된다.
soup = BeautifulSoup(data.text, 'html.parser')

# select를 이용해서, li들을 불러오기
# class 명 앞에는 '.'을 붙여줍니다.
# class 명 내의 띄어쓰기(공백)은 '.'으로 바꾸어 써주세요.
# class는 맨 뒤에 것을 가져옴
movies = soup.select_one('#__next > main > div > div.ipc-page-content-container.ipc-page-content-container--center > section > div > div.ipc-page-grid.ipc-page-grid--bias-left > div > ul')

for movie in movies:
    tag_element = movie.select_one('.ipc-title__text')
    if not tag_element:
        continue
    
    # 영화번호.영화 제목 가져오기.
    print(tag_element.text)
    
    # 영화 개봉 연도 가져오기
    released_year = movie.select_one('.cli-title-metadata > span:nth-child(1)')
    print(released_year.text)
    
    # 영화 상영시간 가져오기
    running_time = movie.select_one('.cli-title-metadata > span:nth-child(2)')
    print(running_time.text)
    
    # 영상물 등급 가져오기
    pg_level = movie.select_one('.cli-title-metadata > span:nth-child(3)')
    print(pg_level.text)
```
![image](https://github.com/user-attachments/assets/0bb7a928-d490-4fdc-a9c7-36832370d802)
